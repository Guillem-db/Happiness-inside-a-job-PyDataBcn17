{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From tables to graphs (draft version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('clean_data/comments_ml.csv',parse_dates=[-3]).drop('Unnamed: 0',axis=1)\n",
    "votes = pd.read_csv('clean_data/votes_ml.csv',parse_dates=[-4]).drop('Unnamed: 0',axis=1)\n",
    "inters = pd.read_csv('clean_data/interactions_ml.csv').drop('Unnamed: 0',axis=1)\n",
    "target = pd.read_csv('clean_data/target_ml.csv').rename(columns={'votes_num':'target'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Employee Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Vote features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vote_feats = votes.groupby(['uid'])['vote'].agg({'votes_1': lambda x: len(x[x==1]),\n",
    "                                                        'votes_2': lambda x: len(x[x==2]),\n",
    "                                                        'votes_3': lambda x: len(x[x==3]),\n",
    "                                                        'votes_4': lambda x: len(x[x==4]),\n",
    "                                                        'votes_mean': lambda x: x.mean(),\n",
    "                                                        'votes_std': lambda x: x.std(),\n",
    "                                                       'votes_num': lambda x: len(x),\n",
    "                                                       }).copy().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Comments features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_feats = comments.groupby(['uid'])['likes'].agg({\n",
    "                                          'likes_num': lambda x: len(x),\n",
    "                                          'likes_mean': lambda x: x.mean(),\n",
    "                                          'likes_std': lambda x: x.std(),\n",
    "                                          'likes_sum': lambda x: x.sum(),\n",
    "                                                       })\n",
    "dislikes_feats = comments.groupby(['uid'])['dislikes'].agg({\n",
    "                                          'dislikes_num': lambda x: len(x),\n",
    "                                          'dislikes_mean': lambda x: x.mean(),\n",
    "                                          'dislikes_std': lambda x: x.std(),\n",
    "                                          'dislikes_sum': lambda x: x.sum(),\n",
    "                                                       })\n",
    "coms_feats = comments.dropna().groupby(['uid'])['comment'].agg({'com_num': lambda x: len(x),\n",
    "                                                             'com_mean': lambda x: x.apply(len).mean(),\n",
    "                                                             'com_std': lambda x: x.map(len).std(),\n",
    "                                                             'com_sum': lambda x: x.map(len).sum()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Merge all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.merge(vote_feats,likes_feats,left_index=True,right_index=True,how='outer')\n",
    "features = pd.merge(features,dislikes_feats,left_index=True,right_index=True,how='outer')\n",
    "features = pd.merge(features,coms_feats,left_index=True,right_index=True,how='outer')\n",
    "features = pd.merge(features,target,left_index=True,right_on='uid',how='right')#fill users with 0 comments\n",
    "E_features = features.copy()\n",
    "E_features.rename(columns=dict([(x,'E_'+str(x)) for x in E_features.columns]),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_features.to_csv('features/e_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['votes_2', 'votes_std', 'votes_3', 'votes_num', 'votes_mean', 'votes_1',\n",
       "       'votes_4', 'likes_num', 'likes_std', 'likes_mean', 'likes_sum',\n",
       "       'dislikes_mean', 'dislikes_std', 'dislikes_num', 'dislikes_sum',\n",
       "       'com_std', 'com_mean', 'com_num', 'com_sum', 'uid', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph employee features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def link_all(users_index,comments,inter):\n",
    "    \"\"\"Returns a graph containing relationships of like/dislike among employees\"\"\"\n",
    "    g = nx.DiGraph()\n",
    "    #One node for every employee storing its employee and company ids\n",
    "    for ix,x in users_index.iterrows():\n",
    "        if not g.has_node(x['uid']):\n",
    "            c,u = x['uid'].split('_')\n",
    "            g.add_node(x['uid'],company=c,employee=u)\n",
    "    #adding links to a graph based on likes/dislikes\n",
    "    com_ids = comments['commentId'].unique()\n",
    "    users = comments['uid'].unique().tolist()\n",
    "    print(\"linking {} comments from {} users\".format(len(com_ids),len(users)))\n",
    "    for com in com_ids:\n",
    "        #who frite current comment\n",
    "        writer = comments[comments['commentId']==com]['uid'].values[0]\n",
    "        #info about com\n",
    "        df = inter[inter['commentId']==com]\n",
    "        #people who disliked the comment\n",
    "        haters = df[df['liked']==0]['uid'].values.copy().tolist()\n",
    "        #people who like the comment\n",
    "        likers = df[df['liked']==1]['uid'].values.copy().tolist()\n",
    "        for i,u in enumerate(likers):\n",
    "            if not g.has_edge(u,writer):\n",
    "                g.add_edge(u,writer,int_sum=1,interactions=1,liked=1,disliked=0)\n",
    "            else:\n",
    "                g.edge[u][writer]['interactions'] += 1\n",
    "                g.edge[u][writer]['int_sum'] += 1\n",
    "                g.edge[u][writer]['liked'] += 1\n",
    "\n",
    "        for i,u in enumerate(haters):\n",
    "            if not g.has_edge(u,writer):\n",
    "                g.add_edge(u,writer,int_sum=-1,interactions=1,liked=0,disliked=1)\n",
    "            else:\n",
    "                g.edge[u][writer]['interactions'] += 1\n",
    "                g.edge[u][writer]['disliked'] += 1\n",
    "                g.edge[u][writer]['int_sum'] -= 1\n",
    "    return g     \n",
    "\n",
    "def add_info_to_graph(features,G):\n",
    "    \"\"\"Adds the information contained in a DataFrame to a networkx graph\"\"\"\n",
    "    for n in G.nodes_iter():\n",
    "        fs = features.ix[n].to_dict()\n",
    "        G.add_node(n,**fs)\n",
    "    return G\n",
    "\n",
    "def add_rel_likes_metrics(g):\n",
    "    \"\"\"Adds infomation to edges about the relative number of likes a given employee gave to another.\"\"\"\n",
    "    for src in g.nodes_iter():\n",
    "        t_rel = 0\n",
    "        neigh = nx.neighbors(g,src)\n",
    "        f = 1 if len(neigh)==0 else len(neigh)\n",
    "        for dst in neigh:\n",
    "            rel = g.edge[src][dst]['liked']/g.edge[src][dst]['interactions']\n",
    "            g.edge[src][dst]['rel_agree'] = rel\n",
    "            t_rel += rel\n",
    "        g.node[src]['mean_agree'] = t_rel/f\n",
    "\n",
    "def calculate_metrics(g,metrics,weight=None):\n",
    "    \"\"\"Returns a DataFrame containing the metrics of a given graph.\n",
    "    It will calculate the metrics both in the directed and  undirected version opf the graph\"\"\"\n",
    "    graph_df = pd.DataFrame()\n",
    "    nw =  '' if weight is None else weight+'_'\n",
    "    for met in metrics:\n",
    "        graph_df['G_'+nw+met.__name__] = pd.Series(met(g))\n",
    "        graph_df['G_'+nw+'w_'+met.__name__] = pd.Series(met(g,weight=weight))\n",
    "        graph_df['G_'+nw+met.__name__+'_u'] = pd.Series(met(g.to_undirected()))\n",
    "        graph_df['G_'+nw+'w_'+met.__name__+'_u'] = pd.Series(met(g.to_undirected(),weight=weight))\n",
    "    #Normalize metrics from 0 to 1\n",
    "    graph_df = (graph_df-graph_df.min(axis=0))/(graph_df.max(axis=0)-graph_df.min(axis=0))\n",
    "    return graph_df\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "def get_clusters(g, weight=None,n_components=2,companyAlias=''):\n",
    "    \"\"\"Return a DataFrame containing the NMF clustering information of a given graph\"\"\"\n",
    "    nw =  '' if weight is None else weight+'_'\n",
    "    #Calculate on directed version of the graph\n",
    "    model = NMF(n_components=n_components)\n",
    "    X = nx.adjacency_matrix(g,weight=weight).todense()\n",
    "    if (X < 0).any():\n",
    "        X = np.abs(X)#NMF only accepts non-negative values\n",
    "    communities = model.fit_transform(X)\n",
    "    cd = pd.DataFrame(index=list(g.nodes_iter()),\n",
    "                      columns=['G_'+nw+'NMF'+str(i)+'_d' for i in range(1,n_components+1)],\n",
    "                      data=communities) \n",
    "    #Undirected version\n",
    "    Xd = nx.adjacency_matrix(g.to_undirected(),weight=weight).todense()\n",
    "    if (Xd < 0).any():\n",
    "        Xd = np.abs(Xd)\n",
    "    communities = model.fit_transform(Xd)\n",
    "    clusters = cd.combine_first(pd.DataFrame(index=cd.index,\n",
    "                                             columns=['G_'+nw+'NMF'+str(i)+'_u' for i in range(1,n_components+1)]\n",
    "                                             ,data=communities))\n",
    "    return clusters \n",
    "\n",
    "def calculate_graph_features(G,features):\n",
    "    add_rel_likes_metrics(G)\n",
    "    ng = add_info_to_graph(features=features,G=G.copy())\n",
    "    \n",
    "    met_funcs = [nx.degree, nx.betweenness_centrality]\n",
    "    graph_met_rel = calculate_metrics(ng,met_funcs,weight='rel_agree')\n",
    "    cluster_rel = get_clusters(ng,weight='rel_agree')\n",
    "    agree_feats = pd.merge(graph_met_rel,cluster_rel,left_index=True,right_index=True,how='outer')\n",
    "    graph_met_int = calculate_metrics(ng,met_funcs,weight='interactions')\n",
    "    cluster_int = get_clusters(ng,weight='interactions')\n",
    "    int_feats = pd.merge(graph_met_int,cluster_int,left_index=True,right_index=True,how='outer')\n",
    "    graph_feats = pd.merge(int_feats,agree_feats,left_index=True,right_index=True,how='outer')\n",
    "    #final_features = pd.merge(features,graph_feats,left_index=True,right_index=True,how='outer')\n",
    "    ng = add_info_to_graph(features=graph_feats,G=ng.copy())\n",
    "    \n",
    "    return graph_feats,ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linking 17919 comments from 900 users\n"
     ]
    }
   ],
   "source": [
    "G_raw = link_all(target,comments,inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G_interactions_degree</th>\n",
       "      <th>G_interactions_w_degree</th>\n",
       "      <th>G_interactions_degree_u</th>\n",
       "      <th>G_interactions_w_degree_u</th>\n",
       "      <th>G_interactions_betweenness_centrality</th>\n",
       "      <th>G_interactions_w_betweenness_centrality</th>\n",
       "      <th>G_interactions_betweenness_centrality_u</th>\n",
       "      <th>G_interactions_w_betweenness_centrality_u</th>\n",
       "      <th>G_interactions_NMF1_d</th>\n",
       "      <th>G_interactions_NMF1_u</th>\n",
       "      <th>...</th>\n",
       "      <th>G_rel_agree_degree_u</th>\n",
       "      <th>G_rel_agree_w_degree_u</th>\n",
       "      <th>G_rel_agree_betweenness_centrality</th>\n",
       "      <th>G_rel_agree_w_betweenness_centrality</th>\n",
       "      <th>G_rel_agree_betweenness_centrality_u</th>\n",
       "      <th>G_rel_agree_w_betweenness_centrality_u</th>\n",
       "      <th>G_rel_agree_NMF1_d</th>\n",
       "      <th>G_rel_agree_NMF1_u</th>\n",
       "      <th>G_rel_agree_NMF2_d</th>\n",
       "      <th>G_rel_agree_NMF2_u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_25</th>\n",
       "      <td>0.080952</td>\n",
       "      <td>0.052985</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>0.066792</td>\n",
       "      <td>0.005056</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>0.098374</td>\n",
       "      <td>0.005056</td>\n",
       "      <td>1.389244e-07</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>1.972912e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_259</th>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.056870</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>0.085043</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>3.989625e-07</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>7.842933e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_271</th>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.021584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_277</th>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.028250</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.074004</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>7.124331e-09</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_278</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.080171</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       G_interactions_degree  G_interactions_w_degree  \\\n",
       "0_25                0.080952                 0.052985   \n",
       "0_259               0.090476                 0.056870   \n",
       "0_271               0.023810                 0.004945   \n",
       "0_277               0.061905                 0.012363   \n",
       "0_278               0.066667                 0.024020   \n",
       "\n",
       "       G_interactions_degree_u  G_interactions_w_degree_u  \\\n",
       "0_25                  0.084615                   0.066792   \n",
       "0_259                 0.084615                   0.063670   \n",
       "0_271                 0.023077                   0.003745   \n",
       "0_277                 0.061538                   0.016854   \n",
       "0_278                 0.069231                   0.026841   \n",
       "\n",
       "       G_interactions_betweenness_centrality  \\\n",
       "0_25                                0.005056   \n",
       "0_259                               0.008131   \n",
       "0_271                               0.000000   \n",
       "0_277                               0.000742   \n",
       "0_278                               0.000816   \n",
       "\n",
       "       G_interactions_w_betweenness_centrality  \\\n",
       "0_25                                  0.010556   \n",
       "0_259                                 0.031115   \n",
       "0_271                                 0.002262   \n",
       "0_277                                 0.028250   \n",
       "0_278                                 0.002061   \n",
       "\n",
       "       G_interactions_betweenness_centrality_u  \\\n",
       "0_25                                  0.007113   \n",
       "0_259                                 0.007113   \n",
       "0_271                                 0.000000   \n",
       "0_277                                 0.000343   \n",
       "0_278                                 0.001114   \n",
       "\n",
       "       G_interactions_w_betweenness_centrality_u  G_interactions_NMF1_d  \\\n",
       "0_25                                    0.006652                    0.0   \n",
       "0_259                                   0.001765                    0.0   \n",
       "0_271                                   0.000000                    0.0   \n",
       "0_277                                   0.010724                    0.0   \n",
       "0_278                                   0.001222                    0.0   \n",
       "\n",
       "       G_interactions_NMF1_u         ...          G_rel_agree_degree_u  \\\n",
       "0_25                     0.0         ...                      0.084615   \n",
       "0_259                    0.0         ...                      0.084615   \n",
       "0_271                    0.0         ...                      0.023077   \n",
       "0_277                    0.0         ...                      0.061538   \n",
       "0_278                    0.0         ...                      0.069231   \n",
       "\n",
       "       G_rel_agree_w_degree_u  G_rel_agree_betweenness_centrality  \\\n",
       "0_25                 0.098374                            0.005056   \n",
       "0_259                0.085043                            0.008131   \n",
       "0_271                0.021584                            0.000000   \n",
       "0_277                0.074004                            0.000742   \n",
       "0_278                0.080171                            0.000816   \n",
       "\n",
       "       G_rel_agree_w_betweenness_centrality  \\\n",
       "0_25                           1.389244e-07   \n",
       "0_259                          3.989625e-07   \n",
       "0_271                          0.000000e+00   \n",
       "0_277                          7.124331e-09   \n",
       "0_278                          0.000000e+00   \n",
       "\n",
       "       G_rel_agree_betweenness_centrality_u  \\\n",
       "0_25                               0.007113   \n",
       "0_259                              0.007113   \n",
       "0_271                              0.000000   \n",
       "0_277                              0.000343   \n",
       "0_278                              0.001114   \n",
       "\n",
       "       G_rel_agree_w_betweenness_centrality_u  G_rel_agree_NMF1_d  \\\n",
       "0_25                             1.972912e-19                 0.0   \n",
       "0_259                            7.842933e-19                 0.0   \n",
       "0_271                            0.000000e+00                 0.0   \n",
       "0_277                            0.000000e+00                 0.0   \n",
       "0_278                            0.000000e+00                 0.0   \n",
       "\n",
       "       G_rel_agree_NMF1_u  G_rel_agree_NMF2_d  G_rel_agree_NMF2_u  \n",
       "0_25                  0.0                 0.0            0.000000  \n",
       "0_259                 0.0                 0.0            0.774894  \n",
       "0_271                 0.0                 0.0            0.000000  \n",
       "0_277                 0.0                 0.0            0.000000  \n",
       "0_278                 0.0                 0.0            0.000000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EG_features,g_total = calculate_graph_features(G_raw.copy(),features.set_index('uid'))\n",
    "EG_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EG_features.to_csv('features/eg_feats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Company features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Comapany vote features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp_vote_feats = votes.groupby(['comid'])['vote'].agg({'votes_1': lambda x: len(x[x==1]),\n",
    "                                                        'votes_2': lambda x: len(x[x==2]),\n",
    "                                                        'votes_3': lambda x: len(x[x==3]),\n",
    "                                                        'votes_4': lambda x: len(x[x==4]),\n",
    "                                                        'votes_mean': lambda x: x.mean(),\n",
    "                                                        'votes_std': lambda x: x.std(),\n",
    "                                                       'votes_num': lambda x: len(x),\n",
    "                                                       }).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Comments features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp_likes_feats = comments.groupby(['comid'])['likes'].agg({\n",
    "                                          'likes_num': lambda x: len(x),\n",
    "                                          'likes_mean': lambda x: x.mean(),\n",
    "                                          'likes_std': lambda x: x.std(),\n",
    "                                          'likes_sum': lambda x: x.sum(),\n",
    "                                                       })\n",
    "comp_dislikes_feats = comments.groupby(['comid'])['dislikes'].agg({\n",
    "                                          'dislikes_num': lambda x: len(x),\n",
    "                                          'dislikes_mean': lambda x: x.mean(),\n",
    "                                          'dislikes_std': lambda x: x.std(),\n",
    "                                          'dislikes_sum': lambda x: x.sum(),\n",
    "                                                       })\n",
    "comp_coms_feats = comments.dropna().groupby(['comid'])['comment'].agg({'com_num': lambda x: len(x),\n",
    "                                                             'com_mean': lambda x: x.apply(len).mean(),\n",
    "                                                             'com_std': lambda x: x.map(len).std(),\n",
    "                                                             'com_sum': lambda x: x.map(len).sum()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Merging and aggregating company features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_features = pd.merge(comp_vote_feats,comp_likes_feats,left_index=True,right_index=True,how='outer')\n",
    "comp_features = pd.merge(comp_features,comp_dislikes_feats,left_index=True,right_index=True,how='outer')\n",
    "comp_features = pd.merge(comp_features,comp_coms_feats,left_index=True,right_index=True,how='outer')\n",
    "#features = pd.merge(features,users_index.set_index('uid')[['churn']],left_index=True,right_index=True,how='left')\n",
    "#features.set_index('uid'),'ui\n",
    "comp_df = comp_features.fillna(1)\n",
    "C_features_raw = comp_df.applymap(lambda x: 1 if x==0 else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Creating company wide features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_features = pd.DataFrame(index=target.uid,columns=C_features_raw.columns)\n",
    "for i in range(len(target.uid)):\n",
    "    company = int(C_features.index.values[i].split('_')[0])\n",
    "    C_features.iloc[i,:] = C_features_raw.ix[company].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_features.to_csv('features/c_feats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Employee-Company features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['comid'] = features['uid'].map(lambda x: x.split('_')[0] )\n",
    "comments['comid'] = comments['uid'].map(lambda x: x.split('_')[0] )\n",
    "inters['comid'] = inters['uid'].map(lambda x: x.split('_')[0] )\n",
    "target['comid'] = target['uid'].map(lambda x: x.split('_')[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_feats = features.set_index('uid')[C_features_raw.columns.values.tolist()+['comid']].copy()\n",
    "companies = C_features_raw.index.values.tolist()\n",
    "for comp in companies:\n",
    "    rel_feats.loc[rel_feats['comid']==int(comp)] = rel_feats.loc[rel_feats['comid']==int(comp)]/comp_df.ix[comp]\n",
    "#rel_feats.drop('comid',axis=1,inplace=True)\n",
    "\n",
    "rel_feats.rename(columns=dict([(x,'CE_'+str(x)) for x in rel_feats.columns]),inplace=True)\n",
    "\n",
    "CE_features = rel_feats.copy().fillna(0.)\n",
    "CE_features.to_csv('features/ce_feats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Employee-Company Graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linking 213 comments from 10 users\n",
      "calculating comp : 4\n",
      "linking 2762 comments from 87 users\n",
      "calculating comp : 6\n",
      "linking 1760 comments from 78 users\n",
      "calculating comp : 11\n",
      "linking 3062 comments from 130 users\n",
      "calculating comp : 12\n",
      "linking 905 comments from 27 users\n",
      "calculating comp : 13\n",
      "linking 474 comments from 14 users\n",
      "calculating comp : 16\n",
      "linking 1691 comments from 99 users\n",
      "calculating comp : 17\n",
      "linking 789 comments from 39 users\n",
      "calculating comp : 18\n",
      "linking 1224 comments from 86 users\n",
      "calculating comp : 19\n",
      "linking 233 comments from 7 users\n",
      "calculating comp : 20\n",
      "linking 608 comments from 36 users\n",
      "calculating comp : 21\n",
      "linking 765 comments from 56 users\n",
      "calculating comp : 22\n",
      "linking 487 comments from 23 users\n",
      "calculating comp : 23\n",
      "linking 488 comments from 23 users\n",
      "calculating comp : 24\n",
      "linking 339 comments from 24 users\n",
      "calculating comp : 25\n",
      "linking 18 comments from 1 users\n",
      "calculating comp : 26\n",
      "linking 712 comments from 67 users\n",
      "calculating comp : 29\n",
      "linking 150 comments from 23 users\n",
      "calculating comp : 30\n",
      "linking 449 comments from 21 users\n",
      "calculating comp : 31\n",
      "linking 790 comments from 49 users\n"
     ]
    }
   ],
   "source": [
    "def one_company_graph_data(comp,target,comments,inters,features):\n",
    "    g_comps = {}\n",
    "    feats = pd.DataFrame()\n",
    "    comp = str(comp)\n",
    "    ui = target[target['comid']==comp].copy()\n",
    "    co = comments[comments['comid']==comp].copy()\n",
    "    ints = inters[inters['comid']==comp].copy()\n",
    "    g_c = link_all(ui,co,ints)\n",
    "    if g_c.node!={}:\n",
    "        g_comps[comp] = g_c\n",
    "        _features,g_c = calculate_graph_features(g_c,features[features['CE_comid'].astype(int)==int(comp)].copy())\n",
    "        feats = _features.copy()\n",
    "    return feats,g_comps\n",
    "\n",
    "rgdf,g_comps  = one_company_graph_data(companies[0],target,comments,inters,rel_feats)\n",
    "\n",
    "for comp in companies[1:]:\n",
    "    print(\"calculating comp : {}\".format(comp))\n",
    "    _rgdf,_g_comps  = one_company_graph_data(comp,target,comments,inters,rel_feats)\n",
    "    g_comps.update(_g_comps)\n",
    "    rgdf = pd.concat([rgdf,_rgdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEG_features = rgdf.rename(columns=dict([(x,'CE'+str(x)) for x in rgdf.columns])).copy()\n",
    "CEG_features.to_csv('features/ceg_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
